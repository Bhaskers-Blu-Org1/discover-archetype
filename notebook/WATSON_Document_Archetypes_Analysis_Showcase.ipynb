{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages for Watson Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade \"ibm-watson>=4.0.1\"\n",
    "!pip install --upgrade \"dash>=1.2.0\"\n",
    "!pip install --upgrade \"plotly>=4.1.1\"\n",
    "!rm -rf discover-archetype\n",
    "!git clone -b refactor https://github.com/tonanhngo/discover-archetype.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"discover-archetype/python\")\n",
    "import find_archetype\n",
    "from ibm_watson.natural_language_understanding_v1 import Features,CategoriesOptions,ConceptsOptions,EntitiesOptions,KeywordsOptions,RelationsOptions,SyntaxOptions\n",
    "\n",
    "print('Credentials needed for https://cloud.ibm.com/catalog/services/natural-language-understanding )')\n",
    "\n",
    "NLU_APIKEY = input(prompt='Please enter the API-Key for your Watson NLU service:')\n",
    "NLU_ENDPOINT = \"UPDATE-ME\"\n",
    "\n",
    "# If true, use the IBM Cloud Storage for input and output\n",
    "# If false, use local file system\n",
    "USE_CLOUD_STORE = True\n",
    "\n",
    "# Configure the following if using IBM Object Cloud Storage\n",
    "# This is needed for running your notebook on Watson Studio, but can also be used when running your notebook locally\n",
    "PATH = {}\n",
    "if USE_CLOUD_STORE:\n",
    "    PATH['dictation_bucket'] = \"dictations\"\n",
    "    PATH['nlu_bucket'] = \"output-nlu\"\n",
    "    PATH['cos_dictation_apikey'] = input(prompt='Please enter the API-Key for your dictation bucket in IBM Cloud Object Storage:')\n",
    "    PATH['cos_dictation_crn'] = \"UPDATE-ME\"\n",
    "    PATH['cos_dictation_endpoint'] = \"UPDATE-ME\"\n",
    "    PATH['cos_dictation_auth_endpoint'] = \"UPDATE-ME\"\n",
    "    \n",
    "    PATH['cos_nlu_apikey'] = input(prompt='Please enter API-Key for your NLU bucket in IBM Cloud Object Storage:')\n",
    "    PATH['cos_nlu_crn'] = \"UPDATE-ME\"\n",
    "    PATH['cos_nlu_endpoint'] = \"UPDATE-ME\"\n",
    "\n",
    "else:\n",
    "    # Where to load data from and save data to\n",
    "    PATH['data']    = '../data/Documents/'\n",
    "    PATH['results'] = './Watson-nlu-results/'\n",
    "\n",
    "NLU = {}\n",
    "NLU['apikey']         = NLU_APIKEY\n",
    "NLU['apiurl']         = NLU_ENDPOINT\n",
    "NLU['version']        = '2019-07-12'\n",
    "NLU['features']       = Features(\n",
    "                        categories= CategoriesOptions(),\n",
    "                        concepts  = ConceptsOptions(),\n",
    "                        entities  = EntitiesOptions(),\n",
    "                        keywords  = KeywordsOptions(),\n",
    "                        relations = RelationsOptions(),\n",
    "                        syntax    = SyntaxOptions()\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 17,
        "hidden": false,
        "row": 17,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# EXPLORING ARCHETYPES\n",
    "\n",
    "When exploring the dimensionality of the problem we used SVD - the 'singular value decomposition' of a matrix of data. Now we move on to Archetypal analysis, a type of 'soft clustering'. \n",
    "\n",
    "The relationship between SVD and Archetypes/Cluster representations is not unlike the relation between waves and particles, where SVD is more like an overlay of multiple waves, like jpeg uses the fourier/cosine transform to decompose pictures, while Archetypes/Clusters are more like representing the picture as a sum of objects. The dimensionality distribution in SVD is not unlike the frequency distribution in a jpeg, although much less restricted. Fourier/Cosine transform has its basis functions predefined and has to stick to its delocalized functions, while SVD is more flexible in its choice of basis functions. The don't have to be delocalized, even if they often are. In fact, the clustering/Archetypal analysis trades information quality in return for intuitive interpretability. It is easier to understand a sum of objects than an overlay of waves. The key difference is that waves have phase, they have both negative and positive amplitude. Objects, on the other hand, never have negative presence - the presence of objects always add up, they can't cancel each other out like waves do. This explains the name of the method we use for computing the Archetypes/Clusters: \"Non-Negative Matrix Factorization\" (NMF). SVD factorizes a matrix into orthogonal components that can have either negative of positive matrix elements. NMF requires that all matrix elements are positive. NMF does, however, still allow delocalization. In straightforward clustering models, an element belongs to one or the other cluster. NMF is an example of \"soft clustering\" where an element can belong to several clusters, just like a word can belong to several overlapping categories. \n",
    "\n",
    "Since NMF has more restrictions than SVD, we assume that SVD is a lower limit for the dimensionality reduction that can be achieved through NMF. According to the same line of reasoning, the overlap between two different Archetypes/Soft Clusters can't be smaller than zero. The overlap between two different modes of 'waves' in SVD will always be zero. \n",
    "\n",
    "With this in mind we now identify the Archetypes of our corpus of dictations by computing the NMF-clusters. \n",
    "\n",
    "Here below we choose to partition our corpus into six archetypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSTANTIATE THE WatsonDocumentArchetypes OBJECT as 'wda' \n",
    "# Split dictations into train/test-set with 5% set aside as test-dictations\n",
    "wda    = find_archetype.WatsonDocumentArchetypes(PATH,NLU,train_test = 0.05, random_state = 42, use_cloud_store = USE_CLOUD_STORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 34,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# BUILDING THE ARCHETYPES\n",
    "\n",
    "\n",
    "In the plots below the different archetypes are shown and compared. Each plot is organized so that one (key) archetype is plotted in order from its largest variable and downwards. The other archetypes' values for the same components are shown for comparison. \n",
    "\n",
    "The list is truncated where the key archetype's component values go below 10% of the strongest component. \n",
    "\n",
    "## 1. FROM ENTITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import show_archetype\n",
    "fig = show_archetype.plot_archetypes(wda, 'entities')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## 2. FROM CONCEPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 9,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "fig = show_archetype.plot_archetypes(wda, 'concepts')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 4,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## 3. FROM KEYWORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 12,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = show_archetype.plot_archetypes(wda, 'keywords')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 53,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# USING THE ARCHETYPES AS A COORDINATE SYSTEM FOR DOCUMENTS\n",
    "\n",
    "We apply hierarchical clustering (dendrograms) to organize the dictations so that the clustering ones are put next to each other. We see that they are quite distinct. \n",
    "\n",
    "The columns represent the six archetypes, the rows are the dictations. \n",
    "\n",
    "The dictations are normalized so that the sum of coefficients over the archetypes sum up to exactly one for each dictation. A row with a completely white segment will therefore be completely black otherwise, indicating that 100% of he dictation belongs to the 'white' archetype. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 4,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## ENTITY-ARCHETYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 14,
        "hidden": false,
        "row": 60,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "## ARCHETYPES based on ENTITIES in corpus texts\n",
    "show_archetype.plot_coordinate(wda, \"entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 60,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## CONCEPT - ARCHETYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 12,
        "hidden": false,
        "row": 60,
        "width": 4
       },
       "report_default": {}
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ARCHETYPES based on CONCEPTS in corpus texts\n",
    "show_archetype.plot_coordinate(wda,'concepts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 64,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## KEYWORD-ARCHETYPES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 12,
        "hidden": false,
        "row": 68,
        "width": 4
       },
       "report_default": {}
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## ARCHETYPES based on KEYWORDS in corpus texts\n",
    "show_archetype.plot_coordinate(wda,'keywords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 12,
        "hidden": false,
        "row": 80,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# ANALYZING NEW DOCUMENTS \n",
    "\n",
    "**SCENARIO**: \n",
    "1. A physician dictates notes after examining a patient. \n",
    "2. The dictation is automatically transcribed. \n",
    "3. The dictation (transcript) is analyzed by Watson NLU, returning entities/concepts/keywords as shown above.\n",
    "4. The analysis is mapped onto the archetypes shown above and returned to the physician. \n",
    "\n",
    "Note that we do not include the new document in the corpus.\n",
    "\n",
    "Here we will go through steps 3-4, assuming that 1-2 have already been performed. \n",
    "\n",
    "## 2. Analyzing a New Transcript\n",
    "\n",
    "We emulate a new transcript by picking one from our test set. Not included in the corpus. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 43,
        "hidden": false,
        "row": 92,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "## We emulate a new transcript by picking one from our test set. Not included in the corpus. \n",
    "\n",
    "test_name = wda.names_test[1]\n",
    "\n",
    "test_text = wda.dictation_df.loc[test_name]\n",
    "test_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 72,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## 3. RUN WATSON NLU ON TEST DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 12,
        "hidden": false,
        "row": 92,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "## DAVID TO TEAM: See self.watson and self.watson_nlu - which does the Watson analysis \n",
    "## for all documents in the corups. Reuse code?.\n",
    "\n",
    "\n",
    "\n",
    "# ## Call Watson API\n",
    "# def watson_nlu(text, \n",
    "#                typ_list = ['entities','concepts','keywords']):\n",
    "#     module = wda.nlu_model.analyze(text = text, features=NLU['features'])\n",
    "#     result = {}\n",
    "#     for typ in typ_list:\n",
    "#          result[typ] = pd.DataFrame(module.result[typ])\n",
    "#     return result\n",
    "\n",
    "# test_watson = watson_nlu(test_text)\n",
    "\n",
    "test_watson = wda.watson_nlu[test_name]\n",
    "test_watson\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 11,
        "hidden": false,
        "row": 104,
        "width": 5
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "test_watson['concepts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 11,
        "hidden": false,
        "row": 92,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "## Construct the 'concepts'-word vector\n",
    "\n",
    "test_vec = test_watson['concepts'].set_index('text')[['relevance']].apply(find_archetype.norm_dot)\n",
    "test_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 9,
        "height": 14,
        "hidden": false,
        "row": 103,
        "width": null
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## 4. MAP TEST DOCUMENT ON ARCHETYPES \n",
    "\n",
    "### 1:  Similarities to Archetypes\n",
    "\n",
    "We project the test document onto the Archetypes by using **cosine similarities** showing 'how similar' the document is to an archetype. The similarity between an archetype vector **a** and the test document vector **d** is \n",
    "\n",
    "$$\\text{similarity} = {\\mathbf{a} \\cdot \\mathbf{d} \\over \\|\\mathbf{a}\\| \\|\\mathbf{d}\\|}= \\mathbf{\\widehat{a}} \\cdot \\mathbf{\\widehat{d}} $$\n",
    "\n",
    "where the 'hat' represents 'dot-normalized' vectors, such that $ \\mathbf{\\widehat{a}} \\cdot \\mathbf{\\widehat{a} = 1}$\n",
    "\n",
    "**NOTE** that, since the Archetypes are NOT an orthogonal set, projecting the test document onto the Archetypes, i.e. saying 'the test document is this much similar to the first archetype and that much similar to the second archetype' is *NOT* the same as saying 'the test vector can be described as a sum of this much of the first archetype and that much of the second archetype. Because the archetypes have overlap, the overlapping similarities will be erroneously amplified, multiplied by the summation. Consider: A mule is half horse and half donkey. A mule on a hill is half a horse on a hill and half a donkey on a hill, but don't sum that up to a half a horse and half a donkey on *two* hills. When using Archetypes as a basis set, this will be taken into account. We do this in \"Archetypes as a basis set\"\n",
    "\n",
    "Here we will only look at the **projections / similarities** between a document and the archetypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "archetypes = wda.archetypes(typ='concepts',n_archs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 11,
        "hidden": false,
        "row": 135,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "archetypes.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 6,
        "hidden": false,
        "row": 74,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "## Select the subset of features in corpus that cover the test vector.\n",
    "in_common     = list(set(test_vec.index).intersection(set(archetypes.fn.columns)))\n",
    "\n",
    "## Check if the test vector contains new features that are not in corpus\n",
    "beyond_corpus = list(set(test_vec.index) - set(archetypes.fn.columns))\n",
    "\n",
    "## Display\n",
    "in_common, beyond_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 11,
        "hidden": false,
        "row": 115,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Measure the similarities between the test vector and the archetypes\n",
    "show_archetype.plot_similarity(((archetypes.fn[in_common] @ test_vec.loc[in_common]) * 100).applymap(int), \n",
    "                               'MY DOC match with ALL Archetypes-features (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 11,
        "hidden": false,
        "row": 117,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scale_segment = np.sqrt(archetypes.fn.shape[1]/len(test_vec))\n",
    "show_archetype.plot_similarity(((archetypes.fn[in_common]* scale_segment @ test_vec.loc[in_common]) * 100).applymap(int), \n",
    "                               'Archetypes match with MY DOC-feature subset (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 12,
        "hidden": false,
        "row": 146,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 2)\n",
    "compare = archetypes.fn[in_common].T\n",
    "# mx = np.sqrt(archetypes.fn.shape[1]/len(test_vec))\n",
    "mx = 1\n",
    "compare = compare * mx\n",
    "compare['MY DOC'] = test_vec.loc[in_common].apply(find_archetype.scale)\n",
    "compare = compare.sort_values(by='MY DOC', ascending = False)[['MY DOC']+list(compare.columns)[:-1]]\n",
    "plt.figure(figsize = (6,6))\n",
    "sns.heatmap((compare*100).applymap(np.sqrt),linewidths = 1,cbar=False)\n",
    "plt.xlabel('Archetypes')\n",
    "plt.title('Match with Archetypes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 76,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_vec_expanded = pd.DataFrame(test_vec, index = archetypes.f.columns).apply(find_archetype.scale).fillna(-0.1)\n",
    "test_vec_expanded.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 12,
        "hidden": false,
        "row": 146,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "test_vec_expanded = pd.DataFrame(test_vec, index = archetypes.f.columns).apply(find_archetype.scale).fillna(0)\n",
    "\n",
    "sns.set(font_scale = 1.5)\n",
    "compare = archetypes.f.T.apply(find_archetype.scale)\n",
    "compare['MY DOC'] = test_vec_expanded.apply(find_archetype.scale)\n",
    "for ix in archetypes.f.index:\n",
    "    cmp = compare.sort_values(by=ix,ascending=False)[[ix,'MY DOC']]\n",
    "    cmp = cmp[cmp[ix] >0.1]\n",
    "    plt.figure(figsize = (2,6))\n",
    "    sns.heatmap(cmp.applymap(np.sqrt),linewidth = 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# Dimensionality: How diverse is the corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 9,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "## DIMENSIONALITY OF THE CORPUS\n",
    "# Establish with Singular Value Decomposition (principal component analysis) :\n",
    "\n",
    "types = ['keywords','concepts','entities']\n",
    "svde  = {}\n",
    "volume = {}\n",
    "volume_distribution = {}\n",
    "\n",
    "for typ in types:\n",
    "    svde[typ]     = find_archetype.Svd(wda.X_matrix(typ))\n",
    "    volume[typ] = svde[typ].s.sum()\n",
    "    volume_distribution[typ] = svde[typ].s.cumsum()/volume[typ]\n",
    "    plt.plot(volume_distribution[typ],label = typ)\n",
    "plt.title('DIMENSIONALITY OF WATSON DICTATION DATA ANALYSIS OUTPUT')\n",
    "plt.xlabel('Dimensions / max = number of dictations in corpus')\n",
    "plt.ylabel('Volume')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## CONCLUSIONS: \n",
    "## DICTATION WORD/ENTITY/CONCEPTUAL CONTENT IS DIVERSE AND SPREAD OVER MANY DIMENSIONS\n",
    "## ACCESS TO A LARGER CORPUS SHOULD BE VERY HELPFUL!"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
